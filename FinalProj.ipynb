{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO5W3jtBuI1BU4VZek8SxTw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Yogeshkumar170201/Yogeshkumar170201/blob/master/FinalProj.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "DC5QbQDGgvKo"
      },
      "outputs": [],
      "source": [
        "!pip install -q kaggle"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.upload()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "Tf30Wosogxs7",
        "outputId": "db6e5f56-f398-4441-a3cf-62119f14c213"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-b27772f5-a067-4edb-94ed-d934960faaba\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-b27772f5-a067-4edb-94ed-d934960faaba\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-5c2e8a8d365b>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    154\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    155\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle"
      ],
      "metadata": {
        "id": "qNHhiaUYgxuk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "id": "FLGcEizhgxwn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "GwrNQ9qzgxyJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d hasyimabdillah/workoutfitness-video"
      ],
      "metadata": {
        "id": "upEo9f8ggx0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install unzip"
      ],
      "metadata": {
        "id": "uKY8_xvdhS0x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/workoutfitness-video.zip -d /content/datset"
      ],
      "metadata": {
        "id": "z7PW6XfuhS4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "A8r6MqEYhS7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "import mediapipe as mp\n",
        "from google.colab.patches import cv2_imshow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "BVy03-p8hS_C"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mp_holistic = mp.solutions.holistic"
      ],
      "metadata": {
        "id": "9Ir_TH6KhTBT"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the number of frames of a video that will be fed to the model as one sequence.\n",
        "SEQUENCE_LENGTH = 10"
      ],
      "metadata": {
        "id": "5Lfpu8rbhTC3"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def landmarks_extraction(path):\n",
        "  # Declare a list to store video frames.\n",
        "  frames_list = []\n",
        "  # Read the Video File using the VideoCapture object.\n",
        "  video_reader = cv2.VideoCapture(path)\n",
        "\n",
        "  # Get the total number of frames in the video.\n",
        "  video_frames_count = int(video_reader.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "  # Calculate the the interval after which frames will be added to the list.\n",
        "  skip_frames_window = max(int(video_frames_count/SEQUENCE_LENGTH), 1)\n",
        "\n",
        "  # Iterate through the Video Frames.\n",
        "  \n",
        "  for frame_counter in range(SEQUENCE_LENGTH):\n",
        "\n",
        "      # Set the current frame position of the video.\n",
        "      video_reader.set(cv2.CAP_PROP_POS_FRAMES, frame_counter * skip_frames_window)\n",
        "\n",
        "      # Reading the frame from the video. \n",
        "      success, frame = video_reader.read() \n",
        "\n",
        "      # Check if Video frame is not successfully read then break the loop\n",
        "      if not success:\n",
        "          break\n",
        "      # Append the normalized frame into the frames list\n",
        "      frames_list.append(frame)\n",
        "\n",
        "  # Release the VideoCapture object. \n",
        "  video_reader.release()\n",
        "  marks = []\n",
        "  with mp_holistic.Holistic() as holistic:\n",
        "    for i in frames_list:\n",
        "      # Convert frame to RGB\n",
        "      frame = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "      # Detect poses in frame\n",
        "      results = holistic.process(frame)\n",
        "      pose_landmarks = results.pose_landmarks\n",
        "      # print(pose_landmarks)\n",
        "      if pose_landmarks is not None:\n",
        "        landmarks = [(lmk.x, lmk.y, lmk.z) for lmk in pose_landmarks.landmark]\n",
        "        marks.append(np.array(landmarks))\n",
        "  # Return the frames list.\n",
        "  marks = np.array(marks)\n",
        "  return marks"
      ],
      "metadata": {
        "id": "UhbiCqfRhTE5"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Specify the directory containing the dataset. \n",
        "DATASET_DIR = \"datset\"\n",
        "\n",
        "# Specify the list containing the names of the classes used for training. Feel free to choose any set of classes.\n",
        "CLASSES_LIST = os.listdir('/content/datset')\n",
        "NO_OF_CATEGORIES = 5\n",
        "CLASSES_LIST = CLASSES_LIST[:NO_OF_CATEGORIES]"
      ],
      "metadata": {
        "id": "MDdAKTHqhTGd"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset():\n",
        "  marks = []\n",
        "  labels = []\n",
        "  for class_index, class_name in enumerate(CLASSES_LIST):\n",
        "    print(class_index, class_name)\n",
        "    # Display the name of the class whose data is being extracted.\n",
        "    print(f'Extracting Data of Class: {class_name}')\n",
        "\n",
        "    # Get the list of video files present in the specific class name directory.\n",
        "    files_list = os.listdir(os.path.join(DATASET_DIR, class_name))\n",
        "\n",
        "    # Iterate through all the files present in the files list.\n",
        "    for file_name in files_list:\n",
        "\n",
        "      # Get the complete video path.\n",
        "      video_file_path = os.path.join(DATASET_DIR, class_name, file_name)\n",
        "\n",
        "      # Extract the landmarks of the video file.\n",
        "      landmarks = landmarks_extraction(video_file_path)\n",
        "      marks.append(np.array(landmarks))\n",
        "      labels.append(class_index)\n",
        "  return marks, labels"
      ],
      "metadata": {
        "id": "4TK0JUPzhTMm"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "marks, labels = create_dataset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "0X7b0I5fgx2J",
        "outputId": "fc3c8629-bfae-4fec-bac0-5ebd48464166"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 hammer curl\n",
            "Extracting Data of Class: hammer curl\n",
            "1 push-up\n",
            "Extracting Data of Class: push-up\n",
            "2 incline bench press\n",
            "Extracting Data of Class: incline bench press\n",
            "3 bench press\n",
            "Extracting Data of Class: bench press\n",
            "4 hip thrust\n",
            "Extracting Data of Class: hip thrust\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels = np.array(labels)\n",
        "marks = np.array(marks)\n",
        "x = marks\n",
        "y = labels"
      ],
      "metadata": {
        "id": "1GnNWr8Pgx39",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a4a25c1e-3320-481e-8c68-03f06df530d3"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-021d6fe70071>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  marks = np.array(marks)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "qENzqcFAgx5d",
        "outputId": "3b7e7ecd-344c-4ca3-e473-bd5b805548e0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(187,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(x)):\n",
        "  if x[i].size!=0:\n",
        "    x[i] = x[i].reshape(x[i].shape[0], -1)"
      ],
      "metadata": {
        "id": "JKmlPE01gx7p"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)"
      ],
      "metadata": {
        "id": "p5GEyaMkgx9n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "07f953d2-b6cc-43da-bbb6-fdba28ca3442"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(187,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in reversed(range(len(x))):\n",
        "  if x[i].size==0:\n",
        "    x = np.delete(x, i)\n",
        "    y = np.delete(y, i)"
      ],
      "metadata": {
        "id": "KaKTHX9Igx_q"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in reversed(range(len(x))):\n",
        "  if x[i].shape[0]<SEQUENCE_LENGTH:\n",
        "    x = np.delete(x, i)\n",
        "    y = np.delete(y, i)\n",
        "  elif x[i].shape[0]>=SEQUENCE_LENGTH:\n",
        "    x[i] = x[i][:SEQUENCE_LENGTH, ]"
      ],
      "metadata": {
        "id": "mqn5iG4VgyDK"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "t0JtmPR_iKNO",
        "outputId": "32f16309-ff49-4714-cf8c-0af119b0d57c"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132,)\n",
            "(132,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "faaBBgyBiKPT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "04be0161-319f-4b51-deab-fc4e2ae5ade8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = tf.keras.utils.to_categorical(z).astype(int)\n",
        "print(z.shape)"
      ],
      "metadata": {
        "id": "myfx7VgBiKRc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d547ef65-e5e3-4c2b-9b5c-548e783b6a15"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(132, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(z)"
      ],
      "metadata": {
        "id": "YCcilhjLiKTq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "285dbabb-e0e1-474f-bf9e-753fbb129fda"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 0 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the LSTM model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.LSTM(128, input_shape=(SEQUENCE_LENGTH, 99)),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(64, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(32, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(16, activation='relu'),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(NO_OF_CATEGORIES, activation='softmax')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "-QkTNmI4iKVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "83e5a5c6-abc3-4a14-f14f-aa91e0392fa7"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_1 (LSTM)               (None, 128)               116736    \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 16)                0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 5)                 85        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 127,685\n",
            "Trainable params: 127,685\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(x, z, test_size=0.25, random_state=42)"
      ],
      "metadata": {
        "id": "um9xk6VOiKX_"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(X_train)):\n",
        "  X_train[i] = tf.constant(X_train[i])\n",
        "for i in range(len(X_test)):\n",
        "  X_test[i] = tf.constant(X_test[i])"
      ],
      "metadata": {
        "id": "WSJZG5O4iKaP"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = tf.TensorArray(dtype=tf.float64, size=0, dynamic_size=True)\n",
        "x_test = tf.TensorArray(dtype=tf.float64, size=0, dynamic_size=True)\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "  x_train = x_train.write(i, tf.constant(X_train[i]))\n",
        "\n",
        "for i in range(len(X_test)):\n",
        "  x_test = x_test.write(i, tf.constant(X_test[i]))\n",
        "y_train = tf.constant(y_train)\n",
        "y_test = tf.constant(y_test)\n",
        "print(type(x_train))\n",
        "print(type(x_test))"
      ],
      "metadata": {
        "id": "6yWVzLvEiaTa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "4cc25f3e-c9f9-4606-e056-e5ef35eecf68"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>\n",
            "<class 'tensorflow.python.ops.tensor_array_ops.TensorArray'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = x_train.stack()\n",
        "x_test = x_test.stack()\n",
        "y_train = y_train.stack()\n",
        "y_test = y_test.stack()"
      ],
      "metadata": {
        "id": "C0uUQ9txiaVr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "outputId": "880318d9-8ebf-4c6e-acfc-b1192eae75af"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-56-01f5c70ae757>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0mnp_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_numpy_behavior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m       \"\"\")\n\u001b[0;32m--> 443\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'tensorflow.python.framework.ops.EagerTensor' object has no attribute 'stack'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', patience=5)\n",
        "model.fit(x_train, y_train, validation_data=(x_test, y_test), epochs=500, batch_size=40, callbacks=[early_stopping])"
      ],
      "metadata": {
        "id": "1HkiLagdowxx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3c7c5f8f-e661-45b5-b38b-64d1fe765db6"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "3/3 [==============================] - 15s 266ms/step - loss: 1.6087 - accuracy: 0.2525 - val_loss: 1.5661 - val_accuracy: 0.2424\n",
            "Epoch 2/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 1.5583 - accuracy: 0.3030 - val_loss: 1.5621 - val_accuracy: 0.2424\n",
            "Epoch 3/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.5408 - accuracy: 0.2828 - val_loss: 1.5068 - val_accuracy: 0.2424\n",
            "Epoch 4/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.4657 - accuracy: 0.4141 - val_loss: 1.4299 - val_accuracy: 0.5758\n",
            "Epoch 5/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.4405 - accuracy: 0.3838 - val_loss: 1.3912 - val_accuracy: 0.4545\n",
            "Epoch 6/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.3657 - accuracy: 0.4646 - val_loss: 1.3077 - val_accuracy: 0.5455\n",
            "Epoch 7/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 1.3894 - accuracy: 0.4747 - val_loss: 1.2208 - val_accuracy: 0.5758\n",
            "Epoch 8/500\n",
            "3/3 [==============================] - 0s 21ms/step - loss: 1.2775 - accuracy: 0.4949 - val_loss: 1.1511 - val_accuracy: 0.5758\n",
            "Epoch 9/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2611 - accuracy: 0.5152 - val_loss: 1.1465 - val_accuracy: 0.5758\n",
            "Epoch 10/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.2177 - accuracy: 0.5354 - val_loss: 1.0490 - val_accuracy: 0.5758\n",
            "Epoch 11/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1495 - accuracy: 0.5859 - val_loss: 0.9848 - val_accuracy: 0.5758\n",
            "Epoch 12/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.1414 - accuracy: 0.5253 - val_loss: 0.9723 - val_accuracy: 0.6970\n",
            "Epoch 13/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 1.0628 - accuracy: 0.5758 - val_loss: 0.8614 - val_accuracy: 0.6970\n",
            "Epoch 14/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.9444 - accuracy: 0.5758 - val_loss: 0.8027 - val_accuracy: 0.6667\n",
            "Epoch 15/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.9672 - accuracy: 0.6162 - val_loss: 0.7805 - val_accuracy: 0.7273\n",
            "Epoch 16/500\n",
            "3/3 [==============================] - 0s 23ms/step - loss: 0.9070 - accuracy: 0.6364 - val_loss: 0.7179 - val_accuracy: 0.7576\n",
            "Epoch 17/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.9934 - accuracy: 0.5758 - val_loss: 0.6473 - val_accuracy: 0.7879\n",
            "Epoch 18/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.7844 - accuracy: 0.6768 - val_loss: 0.6246 - val_accuracy: 0.8788\n",
            "Epoch 19/500\n",
            "3/3 [==============================] - 0s 20ms/step - loss: 0.8398 - accuracy: 0.6869 - val_loss: 0.6203 - val_accuracy: 0.8788\n",
            "Epoch 20/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7727 - accuracy: 0.7475 - val_loss: 0.5988 - val_accuracy: 0.8788\n",
            "Epoch 21/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7467 - accuracy: 0.7071 - val_loss: 0.6390 - val_accuracy: 0.6364\n",
            "Epoch 22/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6789 - accuracy: 0.7071 - val_loss: 0.5672 - val_accuracy: 0.8788\n",
            "Epoch 23/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.7515 - accuracy: 0.6970 - val_loss: 0.5584 - val_accuracy: 0.8788\n",
            "Epoch 24/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.6770 - accuracy: 0.7778 - val_loss: 0.5261 - val_accuracy: 0.8788\n",
            "Epoch 25/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5794 - accuracy: 0.7778 - val_loss: 0.5267 - val_accuracy: 0.8788\n",
            "Epoch 26/500\n",
            "3/3 [==============================] - 0s 19ms/step - loss: 0.6423 - accuracy: 0.7374 - val_loss: 0.5172 - val_accuracy: 0.8485\n",
            "Epoch 27/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5937 - accuracy: 0.7677 - val_loss: 0.4845 - val_accuracy: 0.8788\n",
            "Epoch 28/500\n",
            "3/3 [==============================] - 0s 18ms/step - loss: 0.5237 - accuracy: 0.7980 - val_loss: 0.4535 - val_accuracy: 0.9091\n",
            "Epoch 29/500\n",
            "3/3 [==============================] - 0s 43ms/step - loss: 0.5574 - accuracy: 0.8283 - val_loss: 0.4789 - val_accuracy: 0.9091\n",
            "Epoch 30/500\n",
            "3/3 [==============================] - 0s 28ms/step - loss: 0.5715 - accuracy: 0.7576 - val_loss: 0.4484 - val_accuracy: 0.9091\n",
            "Epoch 31/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4833 - accuracy: 0.8485 - val_loss: 0.4403 - val_accuracy: 0.9091\n",
            "Epoch 32/500\n",
            "3/3 [==============================] - 0s 27ms/step - loss: 0.4643 - accuracy: 0.8182 - val_loss: 0.4325 - val_accuracy: 0.9091\n",
            "Epoch 33/500\n",
            "3/3 [==============================] - 0s 34ms/step - loss: 0.4799 - accuracy: 0.8081 - val_loss: 0.4203 - val_accuracy: 0.9394\n",
            "Epoch 34/500\n",
            "3/3 [==============================] - 0s 26ms/step - loss: 0.4388 - accuracy: 0.8182 - val_loss: 0.4403 - val_accuracy: 0.9091\n",
            "Epoch 35/500\n",
            "3/3 [==============================] - 0s 30ms/step - loss: 0.3892 - accuracy: 0.8687 - val_loss: 0.4609 - val_accuracy: 0.9091\n",
            "Epoch 36/500\n",
            "3/3 [==============================] - 0s 31ms/step - loss: 0.3829 - accuracy: 0.8990 - val_loss: 0.3613 - val_accuracy: 0.9697\n",
            "Epoch 37/500\n",
            "3/3 [==============================] - 0s 33ms/step - loss: 0.4376 - accuracy: 0.8788 - val_loss: 0.3644 - val_accuracy: 0.9697\n",
            "Epoch 38/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.4109 - accuracy: 0.8384 - val_loss: 0.4076 - val_accuracy: 0.9091\n",
            "Epoch 39/500\n",
            "3/3 [==============================] - 0s 35ms/step - loss: 0.4367 - accuracy: 0.8788 - val_loss: 0.4683 - val_accuracy: 0.9091\n",
            "Epoch 40/500\n",
            "3/3 [==============================] - 0s 25ms/step - loss: 0.4186 - accuracy: 0.8485 - val_loss: 0.4043 - val_accuracy: 0.9394\n",
            "Epoch 41/500\n",
            "3/3 [==============================] - 0s 32ms/step - loss: 0.2229 - accuracy: 0.9293 - val_loss: 0.4329 - val_accuracy: 0.9394\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8b24099460>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(x_test, y_test)"
      ],
      "metadata": {
        "id": "KnWgHsdTiKdq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "5fdb13ea-3297-4c70-ac0b-784979301f6c"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 16ms/step - loss: 0.4329 - accuracy: 0.9394\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(loss)\n",
        "print(accuracy)"
      ],
      "metadata": {
        "id": "WCagHLRKiiwD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2d441f5b-d829-4e7e-d829-10f778f751f7"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.4328698217868805\n",
            "0.939393937587738\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "metadata": {
        "id": "fBw1Sjl9iiye",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "231cc9b3-e8b2-4a9d-a85d-5ce0e9e3cab3"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test)"
      ],
      "metadata": {
        "id": "XtlGz5Nmii2C",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3178b47b-7043-4c8c-da55-ea5001cba30b"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [1 0 0 0 0]\n",
            " [1 0 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 0 1 0 0]], shape=(33, 5), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_pred.shape)"
      ],
      "metadata": {
        "id": "tq85jcc4ip9Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "832dcb9e-d046-496f-b311-1eb84b73c663"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(33, 5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QsyTEfy6pakt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_predd = []\n",
        "for i in range(0, y_pred.shape[0]):\n",
        "  label = 0\n",
        "  val = 2.2250738585072014e-308\n",
        "  for j in range(0, NO_OF_CATEGORIES):\n",
        "    if y_pred[i][j] > val:\n",
        "      val = y_pred[i][j]\n",
        "      label = j\n",
        "  y_predd.append(label)"
      ],
      "metadata": {
        "id": "yAeHV3qsip_I"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = []\n",
        "for i in range(0, y_pred.shape[0]):\n",
        "  for j in range(0, NO_OF_CATEGORIES):\n",
        "    if y_test[i][j] == 1:\n",
        "      y_true.append(j)"
      ],
      "metadata": {
        "id": "5kKy7TTaiqBO"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_predd)"
      ],
      "metadata": {
        "id": "dOYU9Xm1ivD1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c1f7010e-d96b-4991-e276-0c6f161cd362"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1, 1, 0, 3, 3, 1, 2, 1, 1, 1, 0, 1, 1, 3, 2, 4, 3, 3, 0, 0, 1, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_true)"
      ],
      "metadata": {
        "id": "oXHMQVJKivGP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d019d2e0-e429-4063-80ee-32cb4c1e342b"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 2, 1, 1, 2, 3, 1, 4, 1, 1, 1, 1, 1, 0, 3, 3, 1, 2, 1, 1, 1, 0, 1, 0, 3, 2, 4, 3, 3, 0, 0, 4, 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cm = confusion_matrix(y_true, y_predd)"
      ],
      "metadata": {
        "id": "MNQHPzl3ivJq"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true, y_predd))"
      ],
      "metadata": {
        "id": "KzCxfrpmiqDG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "18fb72c7-da14-40bd-d705-08f7e7bd94f0"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.80      0.89         5\n",
            "           1       0.88      1.00      0.93        14\n",
            "           2       1.00      1.00      1.00         5\n",
            "           3       1.00      1.00      1.00         6\n",
            "           4       1.00      0.67      0.80         3\n",
            "\n",
            "    accuracy                           0.94        33\n",
            "   macro avg       0.97      0.89      0.92        33\n",
            "weighted avg       0.95      0.94      0.94        33\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install fastdtw"
      ],
      "metadata": {
        "id": "Vn0UHwC0iqFN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "49e7911b-2bed-41dd-a065-97692e7bba4d"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting fastdtw\n",
            "  Downloading fastdtw-0.3.4.tar.gz (133 kB)\n",
            "\u001b[2K     \u001b[90m\u001b[0m \u001b[32m133.4/133.4 KB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from fastdtw) (1.22.4)\n",
            "Building wheels for collected packages: fastdtw\n",
            "  Building wheel for fastdtw (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fastdtw: filename=fastdtw-0.3.4-cp39-cp39-linux_x86_64.whl size=534346 sha256=56ff265f9af1b93dc7360c61a6108a69927bc6f02d3beaaff0c0c6414d4ccf74\n",
            "  Stored in directory: /root/.cache/pip/wheels/1f/a1/63/bfd0fddb5bf0b59f564872e29272cee8a2de0cd745d88fede5\n",
            "Successfully built fastdtw\n",
            "Installing collected packages: fastdtw\n",
            "Successfully installed fastdtw-0.3.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "def extract_features(video_path, num_frames):\n",
        "    # Load the video using OpenCV\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    \n",
        "    # Initialize empty list to store the features\n",
        "    features = []\n",
        "    \n",
        "    # Loop through each frame of the video\n",
        "    while True:\n",
        "        # Read a frame from the video\n",
        "        ret, frame = cap.read()\n",
        "        \n",
        "        # Break the loop if there are no more frames\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        # Resize the frame to 112x112 pixels\n",
        "        frame = cv2.resize(frame, (112, 112))\n",
        "        \n",
        "        # Convert the frame to grayscale\n",
        "        frame_gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        \n",
        "        # Stack 3 copies of the grayscale frame to create a 3-channel image\n",
        "        frame_3channel = np.stack((frame_gray,)*3, axis=-1)\n",
        "        \n",
        "        # Normalize the pixel values between -1 and 1\n",
        "        frame_norm = (frame_3channel - 128) / 128\n",
        "        \n",
        "        # Append the normalized frame to the list of features\n",
        "        features.append(frame_norm)\n",
        "        \n",
        "        # If we have collected enough frames, break out of the loop\n",
        "        if len(features) == num_frames:\n",
        "            break\n",
        "    \n",
        "    # Pad or truncate the frames to match the fixed number of frames\n",
        "    if len(features) < num_frames:\n",
        "        num_pad_frames = num_frames - len(features)\n",
        "        padding = np.zeros((num_pad_frames, 112, 112, 3))\n",
        "        features = np.concatenate((features, padding), axis=0)\n",
        "    elif len(features) > num_frames:\n",
        "        features = features[:num_frames]\n",
        "    \n",
        "    # Convert the list of features to a numpy array\n",
        "    features = np.array(features)\n",
        "    \n",
        "    # Reshape the array to (1, num_frames, height, width, channels)\n",
        "    features = np.reshape(features, (1, features.shape[0], 112, 112, 3))\n",
        "    \n",
        "    # Return the extracted features\n",
        "    return features"
      ],
      "metadata": {
        "id": "Wt4xqBxpiqHn"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "import numpy as np\n",
        "\n",
        "def align_features(f1, f2):\n",
        "    # Reshape the feature arrays\n",
        "    f1 = np.reshape(f1, (f1.shape[0], -1))\n",
        "    f2 = np.reshape(f2, (f2.shape[0], -1))\n",
        "\n",
        "    # Compute the pairwise cosine distances between the features\n",
        "    distances = pairwise_distances(f1, f2, metric='cosine')\n",
        "\n",
        "    # Use the Hungarian algorithm to find the optimal assignment of features\n",
        "    row_ind, col_ind = linear_sum_assignment(distances)\n",
        "\n",
        "    # Sort the assignments in ascending order of row indices\n",
        "    idx = np.argsort(row_ind)\n",
        "    row_ind, col_ind = row_ind[idx], col_ind[idx]\n",
        "\n",
        "    # Select the corresponding features from f1 and f2\n",
        "    aligned_f1, aligned_f2 = f1[row_ind], f2[col_ind]\n",
        "\n",
        "    return aligned_f1, aligned_f2\n"
      ],
      "metadata": {
        "id": "eUwZwxPp5MkL"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def sim_cosine(video1_aligned, video2_aligned):\n",
        "  similarity = cosine_similarity(video1_aligned, video2_aligned)\n",
        "\n",
        "  return similarity\n"
      ],
      "metadata": {
        "id": "qcuXP_335otd"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_category(path):\n",
        "  test_marks = landmarks_extraction(path)\n",
        "  test_marks = np.array(test_marks)\n",
        "  test_marks = test_marks.reshape(test_marks.shape[0], -1)\n",
        "  test_marks = test_marks.reshape(1, SEQUENCE_LENGTH, 99)\n",
        "  test_marks = tf.constant(test_marks)\n",
        "  test_category = model.predict(test_marks)\n",
        "  highest_index = np.argmax(test_category[0])\n",
        "  return highest_index"
      ],
      "metadata": {
        "id": "PoSa3EOJqXcG"
      },
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_of_testvideo =  '/content/pushup2.mp4'"
      ],
      "metadata": {
        "id": "sY9ZEdsniqLK"
      },
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cat = find_category(path_of_testvideo)\n",
        "print(CLASSES_LIST[cat])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "U0fvobwkrzy2",
        "outputId": "e9952e11-4d17-41ad-bac4-fe0730cc5bc1"
      },
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 47ms/step\n",
            "push-up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def excercise_right(path, cat):\n",
        "  mx_sim = 0.00\n",
        "  path_cat = os.path.join('/content/datset/'+CLASSES_LIST[cat]+'/')\n",
        "  videos_list = os.listdir(path_cat)\n",
        "  for i in range(0, len(videos_list)):\n",
        "    video_path = os.path.join(path_cat, videos_list[i])\n",
        "    f1 = extract_features(video_path, 100)\n",
        "    f2 = extract_features(path_of_testvideo, 100)\n",
        "    align_f1, align_f2 = align_features(f1, f2)\n",
        "    sim = sim_cosine(align_f1, align_f2)\n",
        "    if sim>mx_sim:\n",
        "      mx_sim = sim\n",
        "  return mx_sim"
      ],
      "metadata": {
        "id": "5MsLTn9v0wql"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mx_sim = excercise_right(path_of_testvideo, cat)\n",
        "print(mx_sim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "29UPaN-J0wt6",
        "outputId": "85581f40-2288-4e39-d657-11e623bac97f"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.91714401]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if mx_sim > 0.9:\n",
        "  print('Excercise is right')\n",
        "else:\n",
        "  print('Excercise is not right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "ATbTTiy77CAs",
        "outputId": "6caaecf6-3294-449d-fe47-d45997487580"
      },
      "execution_count": 184,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Excercise is right\n"
          ]
        }
      ]
    }
  ]
}